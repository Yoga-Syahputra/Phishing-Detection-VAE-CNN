{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zs8sn_qSYFM"
      },
      "source": [
        "**Mount to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NluVSNvOR-IG",
        "outputId": "64933e08-2b51-49b9-e734-1dba254a3350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgmApTAESkWN"
      },
      "source": [
        "**Import Necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-QOR0q1qWHh5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import seaborn as sns\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F8B8kHxVkfr"
      },
      "source": [
        "1. Load Preprocessed Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXY-XSHZWLC1",
        "outputId": "a6215bdc-4d97-464a-df77-8db10fe56b9a"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.load('/content/drive/MyDrive/Thesis - Undergraduate Ch./Preprocessing/X_train_7000_tensor_most.pt')\n",
        "X_test_tensor = torch.load('/content/drive/MyDrive/Thesis - Undergraduate Ch./Preprocessing/X_test_1500_tensor_most.pt')\n",
        "y_test_tensor = torch.load('/content/drive/MyDrive/Thesis - Undergraduate Ch./Preprocessing/y_test_1500_tensor_most.pt')\n",
        "\n",
        "print(\"Preprocessed tensors loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vySmHjXCkXH6",
        "outputId": "69a87902-f153-43ff-c3b0-12c461848fb7"
      },
      "outputs": [],
      "source": [
        "# Print the output shape for each data\n",
        "print(f\"X_train shape: {X_train_tensor.shape}\")\n",
        "print(f\"X_test shape: {X_test_tensor.shape}\")\n",
        "print(f\"y_test shape: {y_test_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5RwhNiaVnuN"
      },
      "source": [
        "2. Define VAE-CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PmuPUVln8e1",
        "outputId": "709758d0-f121-4473-a02a-cf861e9d0556"
      },
      "outputs": [],
      "source": [
        "#@title Vocabulary = 87 (Dataset 10000: 7000 Legitimate & 1500 Legitimate + 1500 Phishing)\n",
        "class VAE_CNN(nn.Module):\n",
        "    def __init__(self, latent_dim=4):\n",
        "        super(VAE_CNN, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            # the layers can be adjusted based on the input size, in this case, the input is (1, 100, 87)\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Output size (CNN) \n",
        "        self.flattened_size = 128 * 12 * 10 \n",
        "\n",
        "        self.fc_mu = nn.Linear(self.flattened_size, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flattened_size, latent_dim)\n",
        "        self.fc_decode = nn.Linear(latent_dim, self.flattened_size)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # The layers can be adjusted based on the output size, in this case, the expected output is (1, 100, 87)\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # [64,24,20]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # [32,48,40]\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=(5,8), stride=2, padding=0, output_padding=(1,1)),  # [1,100,87]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "      x = self.fc_decode(z)\n",
        "      x = x.view(-1, 128, 12, 10)\n",
        "      x = self.decoder(x)\n",
        "      return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar\n",
        "\n",
        "# Display a summary of the model architecture\n",
        "model = VAE_CNN()\n",
        "summary(model, input_size=[(1, 100, 87)], batch_size=1) # (batch, channels, height, width = N, C, H, W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8iywd9KVy7H"
      },
      "source": [
        "4. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ieGIkMkFTHgO",
        "outputId": "7e66e1cd-79be-48f7-a9cb-030591d8306b"
      },
      "outputs": [],
      "source": [
        "#@title With Hyperparameter Tuning (10,000) - Retrained\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameter candidates\n",
        "latent_dims = [4, 8, 16]\n",
        "learning_rates = [0.001]\n",
        "batch_sizes = [16, 32]\n",
        "num_epochs = 20\n",
        "optimizers = ['Adam']\n",
        "\n",
        "# Loss function\n",
        "mse_loss = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# VAE loss function (Reconstruction Loss + KL Divergence Loss)\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    reconstruction_loss = mse_loss(recon_x, x)\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "    return total_loss, reconstruction_loss, kl_loss\n",
        "\n",
        "# Store all training results\n",
        "results = []\n",
        "\n",
        "# Loop through each combination of hyperparameters\n",
        "for latent_dim in latent_dims:\n",
        "    for lr in learning_rates:\n",
        "        for batch_size in batch_sizes:\n",
        "            for opt_name in optimizers:\n",
        "                print(f\"\\n[Training] latent_dim: {latent_dim}, lr: {lr}, batch_size: {batch_size}, optimizer: {opt_name}\")\n",
        "\n",
        "                # Create DataLoader for each batch size\n",
        "                train_loader = DataLoader(TensorDataset(X_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "                # Initialize model and optimizer\n",
        "                model = VAE_CNN(latent_dim=latent_dim).to(device)\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                train_loss_history = []\n",
        "                recon_loss_history = []\n",
        "                kl_loss_history = []\n",
        "\n",
        "                # Start training timer\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Training loop\n",
        "                for epoch in tqdm(range(num_epochs), desc=f\"Training {latent_dim}, lr {lr}, bs {batch_size}, opt {opt_name}\"):\n",
        "                    model.train()\n",
        "                    total_loss, total_recon_loss, total_kl_loss = 0, 0, 0\n",
        "\n",
        "                    for batch in train_loader:\n",
        "                        x_batch = batch[0].to(device)\n",
        "\n",
        "                        optimizer.zero_grad()\n",
        "                        recon_batch, mu, logvar = model(x_batch)\n",
        "                        loss, recon_loss, kl = vae_loss(recon_batch, x_batch, mu, logvar)\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        total_loss += loss.item()\n",
        "                        total_recon_loss += recon_loss.item()\n",
        "                        total_kl_loss += kl.item()\n",
        "\n",
        "                    avg_loss = total_loss / len(train_loader.dataset)\n",
        "                    avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
        "                    avg_kl_loss = total_kl_loss / len(train_loader.dataset)\n",
        "\n",
        "                    train_loss_history.append(avg_loss)\n",
        "                    recon_loss_history.append(avg_recon_loss)\n",
        "                    kl_loss_history.append(avg_kl_loss)\n",
        "\n",
        "                    tqdm.write(f\"Epoch [{epoch+1}/{num_epochs}] - kl: {avg_kl_loss:.4f} - loss: {avg_loss:.4f} - recon: {avg_recon_loss:.4f}\")\n",
        "\n",
        "                # End training timer\n",
        "                end_time = time.time()\n",
        "                duration = end_time - start_time\n",
        "                print(f\"Training duration: {duration/60:.2f} minutes\")\n",
        "\n",
        "                # Save results\n",
        "                results.append({\n",
        "                    'latent_dim': latent_dim,\n",
        "                    'batch_size': batch_size,\n",
        "                    'optimizer': opt_name,\n",
        "                    'learning_rate': lr,\n",
        "                    'label': f'latent{latent_dim}_lr{lr}_bs{batch_size}_{opt_name}',\n",
        "                    'train_loss_history': train_loss_history,\n",
        "                    'duration': duration\n",
        "                })\n",
        "\n",
        "                # Plot individual loss curves\n",
        "                plt.figure(figsize=(12,6))\n",
        "                plt.plot(train_loss_history, label='Total Loss')\n",
        "                plt.plot(recon_loss_history, label='Reconstruction Loss')\n",
        "                plt.plot(kl_loss_history, label='KL Divergence Loss')\n",
        "                plt.xlabel('Epoch')\n",
        "                plt.ylabel('Loss')\n",
        "                plt.title(f'Loss Curves\\nlatent_dim={latent_dim}, lr={lr}, batch_size={batch_size}, optimizer={opt_name}')\n",
        "                plt.legend()\n",
        "                plt.grid()\n",
        "\n",
        "                # Save plot\n",
        "                plot_path = f\"/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Plots/Fixed/loss_latent{latent_dim}_lr{lr}_bs{batch_size}_opt{opt_name}.png\"\n",
        "                plt.savefig(plot_path)\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "\n",
        "                print(f\"Plot saved: {plot_path}\")\n",
        "\n",
        "                # Save the model\n",
        "                model_path = f\"/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent{latent_dim}_lr{lr}_bs{batch_size}_opt{opt_name}.pth\"\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f\"Model trained and saved successfully at: {model_path}\")\n",
        "\n",
        "# Global comparison: Plot total loss between all hyperparameter combinations\n",
        "plt.figure(figsize=(14,8))\n",
        "for result in results:\n",
        "    plt.plot(result['train_loss_history'], label=f\"{result['label']} ({result['duration']/60:.1f}m)\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Total Loss')\n",
        "plt.title('Comparison of Total Loss between Hyperparameters')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Save global comparison plot\n",
        "comparison_plot_path = \"/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Plots/Fixed/comparison_total_loss_updated.png\"\n",
        "plt.savefig(comparison_plot_path)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(f\"Comparison plot saved: {comparison_plot_path}\")\n",
        "\n",
        "# Plot comparison for each batch size separately\n",
        "batch_sizes_unique = sorted(set([r['batch_size'] for r in results]))\n",
        "\n",
        "for batch_size in batch_sizes_unique:\n",
        "    plt.figure(figsize=(14,8))\n",
        "    batch_results = [r for r in results if r['batch_size'] == batch_size]\n",
        "\n",
        "    for result in batch_results:\n",
        "        plt.plot(result['train_loss_history'], label=f\"{result['label']} ({result['duration']/60:.1f}m)\")\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Total Loss')\n",
        "    plt.title(f'Comparison of Total Loss for Batch Size {batch_size}')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    # Save batch-specific plot\n",
        "    batch_plot_path = f\"/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Plots/Fixed/comparison_total_loss_batch{batch_size}_updated.png\"\n",
        "    plt.savefig(batch_plot_path)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Batch-specific comparison plot saved: {batch_plot_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPeWpRS4V0ys"
      },
      "source": [
        "6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHfVFeveWwbl",
        "outputId": "42d99fb6-29e6-4fb2-e46d-12c0bc1b194d"
      },
      "outputs": [],
      "source": [
        "#@title Load Trained Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = VAE_CNN(latent_dim=8).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent8_lr0.001_bs16_optAdam.pth'))\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2mxBujGlWzLo",
        "outputId": "311b6533-5d07-41b4-a624-d6cb52d18044"
      },
      "outputs": [],
      "source": [
        "#@title Threshold Selection with Percentile\n",
        "\n",
        "# --------------------------\n",
        "# Dataset & DataLoader\n",
        "# --------------------------\n",
        "batch_size = 128\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# --------------------------\n",
        "# Model Evaluation per Batch\n",
        "# --------------------------\n",
        "model.eval()\n",
        "losses, labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        recon, _, _ = model(x)\n",
        "        batch_loss = torch.mean((recon - x) ** 2, dim=(1, 2, 3))\n",
        "        losses.append(batch_loss.cpu())\n",
        "        labels.append(y.cpu())\n",
        "\n",
        "loss_per_sample = torch.cat(losses)\n",
        "labels = torch.cat(labels).int()\n",
        "\n",
        "# --------------------------\n",
        "# Thresholds from Various Percentiles (1%-99%)\n",
        "# --------------------------\n",
        "percentiles = list(range(1, 100))\n",
        "thresholds = [torch.quantile(loss_per_sample[labels == 0], p / 100) for p in percentiles]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\n=== Percentile-based Evaluation ===\")\n",
        "for p, thresh in zip(percentiles, thresholds):\n",
        "    preds = (loss_per_sample > thresh).int()\n",
        "    cm = confusion_matrix(labels, preds)\n",
        "    precision = precision_score(labels, preds, zero_division=0)\n",
        "    recall = recall_score(labels, preds, zero_division=0)\n",
        "    f1 = f1_score(labels, preds, zero_division=0)\n",
        "    results.append((p, thresh.item(), precision, recall, f1))\n",
        "\n",
        "    print(f\"\\n--- Percentile {p}% ---\")\n",
        "    print(f\"Threshold : {thresh.item():.6f}\")\n",
        "    print(f\"Precision : {precision:.4f}\")\n",
        "    print(f\"Recall    : {recall:.4f}\")\n",
        "    print(f\"F1 Score  : {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# --------------------------\n",
        "# Metric vs Percentile Visualization\n",
        "# --------------------------\n",
        "percentiles, thresholds, precisions, recalls, f1s = zip(*results)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(percentiles, precisions, label=\"Precision\", marker='.')\n",
        "plt.plot(percentiles, recalls, label=\"Recall\", marker='.')\n",
        "plt.plot(percentiles, f1s, label=\"F1 Score\", marker='.')\n",
        "plt.xlabel(\"Percentile Threshold\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Precision, Recall, F1 Score vs Threshold Percentile\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --------------------------\n",
        "# Threshold Value vs Percentile Visualization\n",
        "# --------------------------\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(percentiles, thresholds, label=\"Threshold Value\", color='black')\n",
        "plt.xlabel(\"Percentile\")\n",
        "plt.ylabel(\"Threshold\")\n",
        "plt.title(\"Threshold Value vs Percentile\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ne1vzVXkbFVL",
        "outputId": "8d54c311-e398-43e8-8f0f-82210c1a8196"
      },
      "outputs": [],
      "source": [
        "#@title Model Evaluation per Batch\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define models and their corresponding latent dimensions\n",
        "models_info = [\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent4_lr0.001_bs16_optAdam.pth', 'latent_dim': 4},\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent4_lr0.001_bs32_optAdam.pth', 'latent_dim': 4},\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent8_lr0.001_bs16_optAdam.pth', 'latent_dim': 8},\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent8_lr0.001_bs32_optAdam.pth', 'latent_dim': 8},\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent16_lr0.001_bs16_optAdam.pth', 'latent_dim': 16},\n",
        "    {'path': '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/vae_cnn_latent16_lr0.001_bs32_optAdam.pth', 'latent_dim': 16},\n",
        "]\n",
        "\n",
        "# Initialize tracking variables\n",
        "best_f1 = 0\n",
        "best_model_info = {}\n",
        "\n",
        "# Loop through all models\n",
        "for info in models_info:\n",
        "    # Load model\n",
        "    model = VAE_CNN(latent_dim=info['latent_dim']).to(device)\n",
        "    model.load_state_dict(torch.load(info['path']))\n",
        "    model.eval()\n",
        "    print(f\"\\nModel loaded: {info['path']} with latent_dim={info['latent_dim']}\")\n",
        "\n",
        "    # Evaluate model\n",
        "    losses, labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(device)\n",
        "            recon, _, _ = model(x)\n",
        "            batch_loss = torch.mean((recon - x) ** 2, dim=(1, 2, 3))\n",
        "            losses.append(batch_loss)\n",
        "            labels.append(y)\n",
        "\n",
        "    losses = torch.cat(losses)\n",
        "    labels = torch.cat(labels).int().to(device)\n",
        "\n",
        "    # Threshold based on quantile\n",
        "    threshold = torch.quantile(losses[labels == 0], 0.82)\n",
        "    predictions = (losses > threshold).int()\n",
        "\n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(labels.cpu(), predictions.cpu())\n",
        "    precision_val = precision_score(labels.cpu(), predictions.cpu(), zero_division=0)\n",
        "    recall_val = recall_score(labels.cpu(), predictions.cpu(), zero_division=0)\n",
        "    f1_val = f1_score(labels.cpu(), predictions.cpu(), zero_division=0)\n",
        "\n",
        "    print(f\"Precision: {precision_val:.4f}\")\n",
        "    print(f\"Recall   : {recall_val:.4f}\")\n",
        "    print(f\"F1-score : {f1_val:.4f}\")\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(5.5, 4.5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Legitimate', 'Phishing'],\n",
        "                yticklabels=['Legitimate', 'Phishing'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Reconstruction Loss Distribution\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.histplot(losses[labels == 0].cpu().numpy(), bins=50, label='Legitimate', color='green', kde=True, stat='density')\n",
        "    sns.histplot(losses[labels == 1].cpu().numpy(), bins=50, label='Phishing', color='red', kde=True, stat='density')\n",
        "    plt.axvline(threshold.item(), color='black', linestyle='--', label=f'Threshold = {threshold.item():.4f}')\n",
        "    plt.title(\"Reconstruction Loss Distribution\")\n",
        "    plt.xlabel(\"Loss\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Track best model\n",
        "    if f1_val > best_f1:\n",
        "        best_f1 = f1_val\n",
        "        best_model_info = {\n",
        "            'path': info['path'],\n",
        "            'latent_dim': info['latent_dim'],\n",
        "            'precision': precision_val,\n",
        "            'recall': recall_val,\n",
        "            'f1_score': f1_val\n",
        "        }\n",
        "\n",
        "# Print the Best Model Summary\n",
        "print(\"\\n=== Best Model Summary ===\")\n",
        "print(f\"Best model: {best_model_info['path'].split('/')[-1]}, Latent Dim: {best_model_info['latent_dim']}\")\n",
        "print(f\"Precision : {best_model_info['precision']:.4f}\")\n",
        "print(f\"Recall    : {best_model_info['recall']:.4f}\")\n",
        "print(f\"F1-Score  : {best_model_info['f1_score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3mDPZ1_pjjJ"
      },
      "source": [
        "7. Save the Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mhRuSkrpnXz",
        "outputId": "bcfc4f46-1b3c-450d-ffdf-3420cb72ab66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model has been saved to: /content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/Best_Model.pth\n"
          ]
        }
      ],
      "source": [
        "# Save the best model file\n",
        "import shutil\n",
        "\n",
        "# Path target for saving the file\n",
        "best_model_save_path = '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/Best_Model.pth'\n",
        "\n",
        "# Copy the best model\n",
        "shutil.copy(best_model_info['path'], best_model_save_path)\n",
        "\n",
        "print(f\"Best model has been saved to: {best_model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXxMsS4ZnNSk"
      },
      "source": [
        "8. Model Testing with New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp4gMdJh3nFu",
        "outputId": "858b1dc6-a771-4fe3-ace8-6b37b3427882"
      },
      "outputs": [],
      "source": [
        "# Load char_to_idx\n",
        "with open('/content/drive/MyDrive/Thesis - Undergraduate Ch./Preprocessing/vocabulary_tested.json') as f:\n",
        "    char_to_idx = json.load(f)\n",
        "char_to_idx = {k: int(v) for k, v in char_to_idx.items()}\n",
        "\n",
        "vocab_size = len(char_to_idx) + 1\n",
        "max_len = 100\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "# Load Model\n",
        "model = VAE_CNN(latent_dim=8)\n",
        "model.load_state_dict(torch.load(\n",
        "    '/content/drive/MyDrive/Thesis - Undergraduate Ch./Models/Dataset 10000/Training Results/Fixed/Best_Model.pth',\n",
        "    map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Preprocess\n",
        "def preprocess_url(url, char_to_idx, max_len=100, vocab_size=100):\n",
        "    encoded = np.zeros((max_len, vocab_size), dtype=np.float32)\n",
        "    for i, ch in enumerate(url[:max_len]):\n",
        "        if ch in char_to_idx:\n",
        "            encoded[i, char_to_idx[ch]] = 1.0\n",
        "    return torch.tensor(encoded).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "# Test URL\n",
        "new_url = \" \"\n",
        "url_tensor = preprocess_url(new_url, char_to_idx, max_len=max_len, vocab_size=vocab_size)\n",
        "\n",
        "# Predict + Timing\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    reconstructed, _, _ = model(url_tensor)\n",
        "    loss = torch.mean((reconstructed - url_tensor) ** 2).item()\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Decision\n",
        "if loss > threshold:\n",
        "    print(f\"PHISHING (Loss: {loss:.4f})\")\n",
        "else:\n",
        "    print(f\"LEGITIMATE (Loss: {loss:.4f})\")\n",
        "\n",
        "# Display Inference Time\n",
        "duration = (end_time - start_time) * 1000\n",
        "print(f\"Detection Time: {duration:.2f} ms\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
